{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNV6J++kxJsnnh/7g/yr6KU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arifinnasif/Natural-Hazard-Prediction/blob/master/lightnet_on_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_SWR8nHpq5Fo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvLSTM"
      ],
      "metadata": {
        "id": "Xm_46cmzrJIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "        # print(\"size of h_cur\", h_cur.size())\n",
        "        # print(\"size of combined\", combined.size())\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters:\n",
        "        input_dim: Number of channels in input\n",
        "        hidden_dim: Number of hidden channels\n",
        "        kernel_size: Size of kernel in convolutions\n",
        "        num_layers: Number of LSTM layers stacked on each other\n",
        "        batch_first: Whether or not dimension 0 is the batch or not\n",
        "        bias: Bias or no bias in Convolution\n",
        "        return_all_layers: Return the list of computations for all layers\n",
        "        Note: Will do same padding.\n",
        "\n",
        "    Input:\n",
        "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
        "    Output:\n",
        "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
        "            0 - layer_output_list is the list of lists of length T of each output\n",
        "            1 - last_state_list is the list of last states\n",
        "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
        "    Example:\n",
        "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
        "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
        "        >> _, last_states = convlstm(x)\n",
        "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self._check_kernel_size_consistency(kernel_size)\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        b, _, _, h, w = input_tensor.size()\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            # Since the init is done in forward. Can send image size here\n",
        "            hidden_state = self._init_hidden(batch_size=b,\n",
        "                                             image_size=(h, w))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, image_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_kernel_size_consistency(kernel_size):\n",
        "        if not (isinstance(kernel_size, tuple) or\n",
        "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
        "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param"
      ],
      "metadata": {
        "id": "3XtLk06nrU6E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_lstm = ConvLSTM(1,[8],[(5,5)],1, batch_first=True) # 1 channel, 8 hidden channel (from geng), 5x5 kernel, 1 layer(?), batch first -> batch er size input tensor e first e dicci,\n",
        "x = torch.rand((32, 6, 1, 25, 25)) # 32 samples in a batch (batch first), prev 6 hours, 1 channel, 25x25 grid\n",
        "# convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
        "_, last_states = conv_lstm(x)\n",
        "h,c = last_states[0]  # 0 for layer index, 0 for h index\n",
        "# print(last_states[0][1].size())\n",
        "# print(\"-----\")\n",
        "# print(h.size())\n"
      ],
      "metadata": {
        "id": "PEs46RzotKtQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ = torch.rand((32, 6, 50, 50))\n",
        "conv_ = nn.Conv2d(in_channels = 6, out_channels = 6*4, kernel_size = 5, groups = 6, stride = 2, padding = 2)\n",
        "# conv_.weight.data = [None, None, ...].repeat(64, 1, 1, 1)\n",
        "# print(conv_.weight.data.size())\n",
        "conv_(x_).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVIzhbxjO91w",
        "outputId": "8286f5cb-41aa-4e68-9e8f-7cadf51fe920"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 24, 25, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_old(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder_old, self).__init__()\n",
        "    self.prev_hours = 6\n",
        "    self.conv_2 = nn.Conv2d(in_channels = self.prev_hours,\n",
        "                          out_channels = self.prev_hours*4, # each input frame gets mapped to 4 layer\n",
        "                          groups = self.prev_hours,\n",
        "                          kernel_size = 7,\n",
        "                          stride = 2,\n",
        "                          padding = 3)\n",
        "    self.conv_lstm = ConvLSTM(input_dim = 4,\n",
        "                               hidden_dim = [8],\n",
        "                               kernel_size = [(5,5)],\n",
        "                               num_layers = 1,\n",
        "                               batch_first=True)\n",
        "    # print(self.conv_2.weight.data.size())\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    x = self.conv_2(input_tensor.flatten(1,2))\n",
        "    _, last_states = self.conv_lstm(torch.unflatten(x, dim = 1, sizes = (6, 4)))\n",
        "    h,c = last_states[0]\n",
        "\n",
        "    return h,c\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "doNfUNdkAcQU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_channels_for_a_given_time, prev_hours):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.prev_hours = prev_hours\n",
        "    self.hidden_dim = 8\n",
        "    self.stride = 2\n",
        "    self.in_channels_for_a_given_time = in_channels_for_a_given_time\n",
        "    self.conv_2 = nn.Conv2d(in_channels = self.in_channels_for_a_given_time, # one 2d lightnig grid at time t\n",
        "                          out_channels = 4, # from geng\n",
        "                          kernel_size = 7,\n",
        "                          stride = self.stride,\n",
        "                          padding = 3)\n",
        "    self.conv_lstm_cell = ConvLSTMCell(input_dim = 4,\n",
        "                               hidden_dim = self.hidden_dim,\n",
        "                               kernel_size = (5,5),\n",
        "                               bias=True)\n",
        "    # print(self.conv_2.weight.data.size())\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    # x = self.conv_2(input_tensor.flatten(1,2))\n",
        "    # _, last_states = self.conv_lstm(torch.unflatten(x, dim = 1, sizes = (6, 4)))\n",
        "    # h,c = last_states[0]\n",
        "    b, prev_hours, channels, height, width = input_tensor.size()\n",
        "    h,c = self.init_hidden(batch_size=b, image_size=(height // self.stride, width // self.stride))\n",
        "\n",
        "    for t in range(prev_hours):\n",
        "      x = self.conv_2(input_tensor[:, t, :, :, :])\n",
        "      h, c = self.conv_lstm_cell(x, cur_state=[h, c])\n",
        "      return h,c\n",
        "\n",
        "    #####\n",
        "\n",
        "    #     layer_output_list = []\n",
        "    #     last_state_list = []\n",
        "\n",
        "    #     seq_len = input_tensor.size(1)\n",
        "    #     cur_layer_input = input_tensor\n",
        "\n",
        "    #     for layer_idx in range(self.num_layers):\n",
        "\n",
        "    #         h, c = hidden_state[layer_idx]\n",
        "    #         output_inner = []\n",
        "    #         for t in range(seq_len):\n",
        "    #             h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "    #                                              cur_state=[h, c])\n",
        "    #             output_inner.append(h)\n",
        "\n",
        "    #         layer_output = torch.stack(output_inner, dim=1)\n",
        "    #         cur_layer_input = layer_output\n",
        "\n",
        "    #         layer_output_list.append(layer_output)\n",
        "    #         last_state_list.append([h, c])\n",
        "\n",
        "    #     if not self.return_all_layers:\n",
        "    #         layer_output_list = layer_output_list[-1:]\n",
        "    #         last_state_list = last_state_list[-1:]\n",
        "\n",
        "    #     return layer_output_list, last_state_list\n",
        "\n",
        "    # return h,c\n",
        "\n",
        "  def init_hidden(self, batch_size, image_size):\n",
        "      height, width = image_size\n",
        "      return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv_2.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv_2.weight.device))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Prj2dxsgF6ks"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fusion(nn.Module):\n",
        "  def __init__(self, total_in_channels):\n",
        "    super(Fusion,self).__init__()\n",
        "    # h_stacked = torch.cat(h_list, dim = 1)\n",
        "    # sc_stacked = torch.cat(c_list, dim = 1)\n",
        "    self.conv_3 = nn.Conv2d(in_channels = total_in_channels,\n",
        "                            out_channels = 64, # from the paper\n",
        "                            kernel_size=1)\n",
        "    self.conv_4 = nn.Conv2d(in_channels = total_in_channels,\n",
        "                            out_channels = 64, # from the paper\n",
        "                            kernel_size=1)\n",
        "\n",
        "  def forward(self, h_list, c_list):\n",
        "    h_stacked = torch.cat(h_list, dim = 1)\n",
        "    c_stacked = torch.cat(c_list, dim = 1)\n",
        "\n",
        "\n",
        "    h_fused_conved = self.conv_3(h_stacked)\n",
        "    c_fused_conved = self.conv_4(c_stacked)\n",
        "\n",
        "    return h_fused_conved, c_fused_conved\n"
      ],
      "metadata": {
        "id": "W8nizYI4xMwa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels_for_a_given_time, next_hours):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.next_hours = next_hours\n",
        "    self.in_channels_for_a_given_time = in_channels_for_a_given_time\n",
        "    self.conv_5 = nn.Conv2d(in_channels = self.in_channels_for_a_given_time, # single L_{-1} frame\n",
        "                          out_channels = 4, # from geng\n",
        "                          kernel_size = 7,\n",
        "                          stride = 2,\n",
        "                          padding = 3)\n",
        "    self.conv_lstm_cell = ConvLSTMCell(input_dim=4, # output of conv\n",
        "                                       hidden_dim=64, # from geng\n",
        "                                       kernel_size=(5,5), # from geng\n",
        "                                       bias=True)\n",
        "    # print(self.conv_2.weight.data.size())\n",
        "    self.deconv = nn.ConvTranspose2d(in_channels=64, # as previous conv_lstm_cell had 64 hidden dim so the size is [:,64,:,:]\n",
        "                                     out_channels=64, # from geng\n",
        "                                     kernel_size = 7, # from geng\n",
        "                                     stride = 2, # from geng\n",
        "                                     padding = 3,\n",
        "                                     output_padding = 1) # not sure\n",
        "\n",
        "    self.conv_6 = nn.Conv2d(in_channels = 64, # previous deconv\n",
        "                          out_channels = 1, # as it is just one layer\n",
        "                          kernel_size = 1, # from geng\n",
        "                          stride = 1) # from geng\n",
        "\n",
        "  def forward(self, input_tensor_L_neg_1, h, c):\n",
        "    # x = self.conv_2(input_tensor.flatten(1,2))\n",
        "    # _, last_states = self.conv_lstm(torch.unflatten(x, dim = 1, sizes = (6, 4)))\n",
        "    # h,c = last_states[0]\n",
        "    b, _, height, width = input_tensor_L_neg_1.size()\n",
        "\n",
        "    pred_output = []\n",
        "\n",
        "    for i in range(self.next_hours):\n",
        "      # print(\"---\")\n",
        "      x = self.conv_5(input_tensor_L_neg_1)\n",
        "      # print(x.size())\n",
        "      # print(\"dbg\", x.size())\n",
        "      h, c = self.conv_lstm_cell(x, cur_state=[h, c])\n",
        "      # print(h.size())\n",
        "      x = self.deconv(h)\n",
        "      # print(x.size())\n",
        "      x = self.conv_6(x)\n",
        "      # print(x.size())\n",
        "\n",
        "      pred_output.append(x)\n",
        "      # print(\"---\")\n",
        "\n",
        "    pred_output = torch.stack(pred_output, 0).permute(1, 0, 2, 3, 4)\n",
        "    # print(torch.stack(pred_output, 0).size())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return pred_output\n",
        "\n"
      ],
      "metadata": {
        "id": "PJqnIYQz12H-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LightNet, self).__init__()\n",
        "    self.obs_enc = Encoder(in_channels_for_a_given_time=1,\n",
        "                           prev_hours=6)\n",
        "    self.fus = Fusion(8) # total h (or c) channels. as we are going to use just one h from the obs encoder (size of h = [:,8,:,:])\n",
        "    self.pred_dec = Decoder(in_channels_for_a_given_time=1,\n",
        "                            next_hours=6)\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    h,c = self.obs_enc(input_tensor)\n",
        "    h,c = self.fus([h],[c])\n",
        "    out = self.pred_dec(input_tensor[:,-1,:,:,:], h, c)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "m91fU11PQ9c0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LightNet()\n",
        "# x = torch.rand((32, 6, 1, 50, 50)) # [batch_size, prev_hours, input_layer, image_height, image_width]\n",
        "# model(x)"
      ],
      "metadata": {
        "id": "DM8wyIeoSynw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MeteorologicalMeasures(output, target):\n",
        "  output, target = output.to(torch.device(\"cuda\")), target.to(torch.device(\"cuda\"))\n",
        "  true_pos = 0\n",
        "  true_neg = 0\n",
        "\n",
        "  false_pos = 0\n",
        "  false_neg = 0\n",
        "\n",
        "  ytrue = target\n",
        "  ypred = torch.sigmoid(output)\n",
        "  ypred = torch.round(ypred)\n",
        "  true_positives = torch.sum(ytrue * ypred)\n",
        "  possible_positives = torch.sum(ytrue)\n",
        "  POD = true_positives / (possible_positives + 1e-10)\n",
        "  predicted_positives = torch.sum(ypred)\n",
        "  FAR = true_positives / (predicted_positives + 1e-10)\n",
        "  return POD, FAR\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jXX1TM7eV9F8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  data = torch.rand((1024,1,50,50), dtype=torch.double)\n",
        "  data[data>0.5] = 1.0\n",
        "  data[data<0.5] = 0.0\n",
        "  # print(data)\n",
        "  train_pct = 0.7\n",
        "  prev_hours = 6\n",
        "  next_hours = 6\n",
        "  batch_size = 32\n",
        "  start_index_list = list(range(data.size(0) - prev_hours - next_hours))\n",
        "  random.shuffle(start_index_list)\n",
        "  train_start_index_list = start_index_list[:int(len(start_index_list)*train_pct)]\n",
        "  val_start_index_list = start_index_list[int(len(start_index_list)*train_pct):]\n",
        "  # print(\"hello\")\n",
        "\n",
        "  # print(len(train_start_index_list))\n",
        "  # print(len(val_start_index_list))\n",
        "\n",
        "  ## train set creation\n",
        "  train_x_set = []\n",
        "  train_y_set = []\n",
        "  for i in range(len(train_start_index_list) // batch_size):\n",
        "    train_x_batch = []\n",
        "    train_y_batch = []\n",
        "    for j in range(batch_size):\n",
        "      start = train_start_index_list[batch_size * i + j]\n",
        "      train_x_batch.append(data[start:(start+prev_hours),:,:,:])\n",
        "      train_y_batch.append(data[(start+prev_hours):(start+prev_hours+next_hours),:,:,:])\n",
        "\n",
        "    train_x_batch = torch.stack(train_x_batch,0)\n",
        "    train_y_batch = torch.stack(train_y_batch,0)\n",
        "\n",
        "    train_x_set.append(train_x_batch)\n",
        "    train_y_set.append(train_y_batch)\n",
        "\n",
        "  # train_x_set = torch.stack(train_x_set,0)\n",
        "  # train_y_set = torch.stack(train_y_set,0)\n",
        "  # print(train_x_set.size())\n",
        "  # print(train_y_set.size())\n",
        "\n",
        "  ## validation set creation\n",
        "  val_x_set = []\n",
        "  val_y_set = []\n",
        "  for i in range(len(val_start_index_list) // batch_size):\n",
        "    val_x_batch = []\n",
        "    val_y_batch = []\n",
        "    for j in range(batch_size):\n",
        "      start = val_start_index_list[batch_size * i + j]\n",
        "      val_x_batch.append(data[start:(start+prev_hours),:,:,:])\n",
        "      val_y_batch.append(data[(start+prev_hours):(start+prev_hours+next_hours),:,:,:])\n",
        "\n",
        "    val_x_batch = torch.stack(val_x_batch,0)\n",
        "    val_y_batch = torch.stack(val_y_batch,0)\n",
        "\n",
        "    val_x_set.append(val_x_batch)\n",
        "    val_y_set.append(val_y_batch)\n",
        "\n",
        "  # val_x_set = torch.stack(val_x_set,0)\n",
        "  # val_y_set = torch.stack(val_y_set,0)\n",
        "  # print(val_x_set.size())\n",
        "  # print(val_y_set.size())\n",
        "  # print(data[start:(start+prev_hours+next_hours),:,:,:].size())\n",
        "\n",
        "  model.double()\n",
        "  # print(model(train_x_set[0]).size())\n",
        "\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "  epoch = 50\n",
        "\n",
        "  for e in range(epoch):\n",
        "    avg_train_loss = 0\n",
        "    avg_val_loss = 0\n",
        "    avg_train_POD = 0\n",
        "    avg_train_FAR = 0\n",
        "    avg_train_ETS = 0\n",
        "    avg_val_POD = 0\n",
        "    avg_val_FAR = 0\n",
        "    avg_val_ETS = 0\n",
        "    print(\"Epoch [\",e+1,\"/\",epoch,\"]\", end=\" \")\n",
        "    for i in tqdm(range(len(train_x_set))):\n",
        "      data, target = train_x_set[i].to(torch.device(\"cuda\")), train_y_set[i].to(torch.device(\"cuda\"))\n",
        "      optimizer.zero_grad()\n",
        "      # train\n",
        "      model.train()\n",
        "      output = model(data)\n",
        "      train_loss = ce_loss(output, target)\n",
        "      train_POD, train_FAR = MeteorologicalMeasures(output, target)\n",
        "      avg_train_loss = avg_train_loss + train_loss.item()\n",
        "      avg_train_POD = avg_train_POD + train_POD.item()\n",
        "      avg_train_FAR = avg_train_FAR + train_FAR.item()\n",
        "      # avg_train_ETS = avg_train_ETS + train_ETS\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    for i in range(len(val_x_set)):\n",
        "      data, target = val_x_set[i].to(torch.device(\"cuda\")), val_y_set[i].to(torch.device(\"cuda\"))\n",
        "      # val\n",
        "      model.eval()\n",
        "      output = model(data)\n",
        "      val_loss = ce_loss(output, target)\n",
        "      val_POD, val_FAR = MeteorologicalMeasures(output, target)\n",
        "      avg_val_loss = avg_val_loss + val_loss.item()\n",
        "      avg_val_POD = avg_val_POD + val_POD.item()\n",
        "      avg_val_FAR = avg_val_FAR + val_FAR.item()\n",
        "      # avg_val_ETS = avg_val_ETS + val_ETS\n",
        "      # train_loss.backward()\n",
        "      # optimizer.step()\n",
        "    avg_train_loss = avg_train_loss / len(train_x_set)\n",
        "    avg_train_POD = avg_train_POD / len(train_x_set)\n",
        "    avg_train_FAR = avg_train_FAR / len(train_x_set)\n",
        "    avg_train_ETS = avg_train_ETS / len(train_x_set)\n",
        "\n",
        "    avg_val_loss = avg_val_loss / len(val_x_set)\n",
        "    avg_val_POD = avg_val_POD / len(val_x_set)\n",
        "    avg_val_FAR = avg_val_FAR / len(val_x_set)\n",
        "    avg_val_ETS = avg_val_ETS / len(val_x_set)\n",
        "    print(\"train loss\", avg_train_loss,\"|\", \"train POD\", avg_train_POD,\"|\", \"train FAR\", avg_train_FAR)#,\"|\", \"train ETS\", avg_train_ETS)\n",
        "    print(\"val loss\", avg_val_loss,\"|\", \"val POD\", avg_val_POD,\"|\", \"val FAR\", avg_val_FAR)#,\"|\", \"val ETS\", avg_val_ETS)\n",
        "    print()\n",
        "      # if batch_idx % args.log_interval == 0:\n",
        "      # print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "      #             epoch, i * len(data), len(train_loader.dataset),\n",
        "      #             100. * batch_idx / len(train_loader), loss.item()))\n",
        "      #         if args.dry_run:\n",
        "      #             break\n",
        "      # for i in range(opt.steps):\n",
        "      #     print('STEP: ', i)\n",
        "      #     def closure():\n",
        "      #         optimizer.zero_grad()\n",
        "      #         out = seq(input)\n",
        "      #         loss = criterion(out, target)\n",
        "      #         print('loss:', loss.item())\n",
        "      #         loss.backward()\n",
        "      #         return loss\n",
        "      #     optimizer.step(closure)\n",
        "\n",
        "\n",
        "model = LightNet()\n",
        "model.to(torch.device('cuda'))\n",
        "train(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkh2qDiuWOXh",
        "outputId": "8791d2bb-1ccd-4127-ce5c-adc3fbb33b25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [ 1 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374536001660926 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371370665762395 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 2 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.37452006041462 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.3713737655592455 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 3 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374512228648092 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371371584760227 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 4 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374503299822614 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.37137514726955 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 5 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374492631377634 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371381357869897 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 6 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374479314005023 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371392276550842 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 7 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374462517268706 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371411426895219 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 8 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374442334923626 | train POD 0.0 | train FAR 0.0\n",
            "val loss 5.371440229610749 | val POD 0.0 | val FAR 0.0\n",
            "\n",
            "Epoch [ 9 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374418836200408 | train POD 5.1170235542311875e-06 | train FAR 0.36764069262215193\n",
            "val loss 5.371470262555311 | val POD 1.2968763524026676e-05 | val FAR 0.5925925925779981\n",
            "\n",
            "Epoch [ 10 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374391735155702 | train POD 0.00010438406854227688 | train FAR 0.5022473322401219\n",
            "val loss 5.371507754254796 | val POD 0.00012090155815997607 | val FAR 0.4911045798654714\n",
            "\n",
            "Epoch [ 11 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374358458048062 | train POD 0.0002840126503567963 | train FAR 0.5107636703285938\n",
            "val loss 5.37155664594031 | val POD 0.0002927846440477724 | val FAR 0.5004123935804576\n",
            "\n",
            "Epoch [ 12 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374324553858657 | train POD 0.00039161740791713874 | train FAR 0.5245263903412635\n",
            "val loss 5.37159614091391 | val POD 0.00039885713798922006 | val FAR 0.5038083079096903\n",
            "\n",
            "Epoch [ 13 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374288003973471 | train POD 0.0005609734866320551 | train FAR 0.521001036234371\n",
            "val loss 5.371645179296817 | val POD 0.0005304355768493594 | val FAR 0.49696770420713793\n",
            "\n",
            "Epoch [ 14 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374243518809343 | train POD 0.0006962780156483779 | train FAR 0.5245907967211347\n",
            "val loss 5.371700359229387 | val POD 0.0009330369097470832 | val FAR 0.5028958118249651\n",
            "\n",
            "Epoch [ 15 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374202673161323 | train POD 0.0008897625451044256 | train FAR 0.5159045065135234\n",
            "val loss 5.371739952754486 | val POD 0.0008617001280474998 | val FAR 0.49717673905800264\n",
            "\n",
            "Epoch [ 16 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374156111693195 | train POD 0.0012102311080128352 | train FAR 0.516107752736495\n",
            "val loss 5.371776915675202 | val POD 0.0013467122456786316 | val FAR 0.4979339447038043\n",
            "\n",
            "Epoch [ 17 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374108801288893 | train POD 0.0016524382446110332 | train FAR 0.5161104370141655\n",
            "val loss 5.371792266761482 | val POD 0.002326565908936997 | val FAR 0.49803806691513697\n",
            "\n",
            "Epoch [ 18 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374055739287235 | train POD 0.0028812191476836366 | train FAR 0.5182550047486602\n",
            "val loss 5.371799668668263 | val POD 0.0027569648593385467 | val FAR 0.49283188119867205\n",
            "\n",
            "Epoch [ 19 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.374000627883327 | train POD 0.005414208105363811 | train FAR 0.5213082799281241\n",
            "val loss 5.371787488875975 | val POD 0.0021968636315607784 | val FAR 0.4983024906212441\n",
            "\n",
            "Epoch [ 20 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373945121940713 | train POD 0.008807268263554763 | train FAR 0.5171752727676403\n",
            "val loss 5.371808534696444 | val POD 0.0030539973442269 | val FAR 0.4947177153595509\n",
            "\n",
            "Epoch [ 21 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373890291772216 | train POD 0.008928411530757295 | train FAR 0.5173606406659036\n",
            "val loss 5.371811031464265 | val POD 0.004783955872123664 | val FAR 0.49917723500305794\n",
            "\n",
            "Epoch [ 22 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373835663557547 | train POD 0.01905491562710858 | train FAR 0.5151832182961319\n",
            "val loss 5.37186822528794 | val POD 0.011513351106236414 | val FAR 0.4971937635527231\n",
            "\n",
            "Epoch [ 23 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373776093139429 | train POD 0.0159997028153803 | train FAR 0.5183470986140365\n",
            "val loss 5.37211925792755 | val POD 0.019562377611643485 | val FAR 0.4956146668688197\n",
            "\n",
            "Epoch [ 24 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373697148602933 | train POD 0.01724218866106237 | train FAR 0.5173579423488883\n",
            "val loss 5.372453395529043 | val POD 0.023256411466723883 | val FAR 0.4953869392603679\n",
            "\n",
            "Epoch [ 25 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373617797046905 | train POD 0.01781746773537429 | train FAR 0.5188307208281651\n",
            "val loss 5.3724627355539285 | val POD 0.018366905966621945 | val FAR 0.497057584364316\n",
            "\n",
            "Epoch [ 26 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373508227749141 | train POD 0.019648610996814884 | train FAR 0.5198054652283006\n",
            "val loss 5.37249170813271 | val POD 0.021959194919188418 | val FAR 0.4976353817406484\n",
            "\n",
            "Epoch [ 27 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373397520478611 | train POD 0.025826903105683172 | train FAR 0.5191209254540591\n",
            "val loss 5.372546402884374 | val POD 0.029129538061908995 | val FAR 0.49737968930930265\n",
            "\n",
            "Epoch [ 28 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373277348984575 | train POD 0.031030821360251738 | train FAR 0.5187501567115627\n",
            "val loss 5.372640332977829 | val POD 0.03581360445259519 | val FAR 0.4967855985928618\n",
            "\n",
            "Epoch [ 29 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373146959961765 | train POD 0.035337473605510455 | train FAR 0.5188476373065174\n",
            "val loss 5.372763203299125 | val POD 0.04096461991338762 | val FAR 0.49739252637934445\n",
            "\n",
            "Epoch [ 30 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.373002960987025 | train POD 0.040356315209695265 | train FAR 0.5194968388250851\n",
            "val loss 5.372903627086412 | val POD 0.04515473946238241 | val FAR 0.4973073359337352\n",
            "\n",
            "Epoch [ 31 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.372845553638367 | train POD 0.04640603051268705 | train FAR 0.5195804256855326\n",
            "val loss 5.373061413128179 | val POD 0.05061196656927712 | val FAR 0.49674342953180883\n",
            "\n",
            "Epoch [ 32 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.372675983235054 | train POD 0.05345818256611334 | train FAR 0.5196030037770831\n",
            "val loss 5.3732405331096595 | val POD 0.05871732754935058 | val FAR 0.49770476803358854\n",
            "\n",
            "Epoch [ 33 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.37249500197921 | train POD 0.061454549679304346 | train FAR 0.5199198382060394\n",
            "val loss 5.373444915386475 | val POD 0.07034255051559496 | val FAR 0.4975588915579473\n",
            "\n",
            "Epoch [ 34 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.372304785792204 | train POD 0.07049458420047613 | train FAR 0.5195629872956867\n",
            "val loss 5.373659130487561 | val POD 0.08299804809202564 | val FAR 0.49834090214895865\n",
            "\n",
            "Epoch [ 35 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.372110226183288 | train POD 0.08067585416632012 | train FAR 0.51893566025604\n",
            "val loss 5.373853640741394 | val POD 0.09100002807335311 | val FAR 0.4985336365850943\n",
            "\n",
            "Epoch [ 36 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.3719114949727365 | train POD 0.09055686086031552 | train FAR 0.5180710070865593\n",
            "val loss 5.374026270056113 | val POD 0.09551342519757193 | val FAR 0.49900179097139435\n",
            "\n",
            "Epoch [ 37 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.371707050317193 | train POD 0.09969031567221878 | train FAR 0.5177044123244253\n",
            "val loss 5.374189597320848 | val POD 0.09960310346624009 | val FAR 0.49882038717255167\n",
            "\n",
            "Epoch [ 38 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.371502005640391 | train POD 0.1087043563679028 | train FAR 0.5176175811463934\n",
            "val loss 5.374309607317129 | val POD 0.10387797212017404 | val FAR 0.49919033367941396\n",
            "\n",
            "Epoch [ 39 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.371295211395789 | train POD 0.11668137851188008 | train FAR 0.517806272643738\n",
            "val loss 5.374416394682445 | val POD 0.10837164813314372 | val FAR 0.49926246987531553\n",
            "\n",
            "Epoch [ 40 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.371090643864185 | train POD 0.12392161286193115 | train FAR 0.5181725695673957\n",
            "val loss 5.374537746536971 | val POD 0.11675825618904555 | val FAR 0.4993269178008581\n",
            "\n",
            "Epoch [ 41 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.370867757648241 | train POD 0.12939455727720997 | train FAR 0.5185484150129768\n",
            "val loss 5.374708181621015 | val POD 0.12255668681536257 | val FAR 0.49937994081416814\n",
            "\n",
            "Epoch [ 42 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.370634937916654 | train POD 0.13733180593660418 | train FAR 0.5186813847451672\n",
            "val loss 5.374964849515096 | val POD 0.12201241308706035 | val FAR 0.4994597948973411\n",
            "\n",
            "Epoch [ 43 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.37043545569251 | train POD 0.1471627077053269 | train FAR 0.518176503574345\n",
            "val loss 5.375141049437492 | val POD 0.1298282154146131 | val FAR 0.499450426930811\n",
            "\n",
            "Epoch [ 44 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.3702176450037085 | train POD 0.15580607857371376 | train FAR 0.5179869232989721\n",
            "val loss 5.375507102213917 | val POD 0.1405697887784064 | val FAR 0.4993113710121128\n",
            "\n",
            "Epoch [ 45 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.369979699359061 | train POD 0.16128623833748768 | train FAR 0.5179606625980185\n",
            "val loss 5.3757612324955595 | val POD 0.14728409553119648 | val FAR 0.4996374681854738\n",
            "\n",
            "Epoch [ 46 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.369736956409983 | train POD 0.1637883168259728 | train FAR 0.518306016278384\n",
            "val loss 5.375960004089014 | val POD 0.15606579568951695 | val FAR 0.49940407025000666\n",
            "\n",
            "Epoch [ 47 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.369487988461305 | train POD 0.16851238875752944 | train FAR 0.5186356423347487\n",
            "val loss 5.376204795956717 | val POD 0.16344419055108778 | val FAR 0.4993701380191976\n",
            "\n",
            "Epoch [ 48 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.369244667131117 | train POD 0.1740101022423082 | train FAR 0.5187252235623757\n",
            "val loss 5.376434206493818 | val POD 0.1735603973231121 | val FAR 0.49952075618518854\n",
            "\n",
            "Epoch [ 49 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.368998569992329 | train POD 0.17878643620238702 | train FAR 0.5189427076869021\n",
            "val loss 5.3766798279461305 | val POD 0.18352876931009499 | val FAR 0.4994182998088713\n",
            "\n",
            "Epoch [ 50 / 50 ] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [01:11<00:00,  3.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 5.368753049891968 | train POD 0.1832036260217417 | train FAR 0.5189567236874374\n",
            "val loss 5.37694528491005 | val POD 0.19254363573932448 | val FAR 0.499462092090679\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = torch.rand((32, 6, 1, 50, 50))\n",
        "# enc = Encoder()\n",
        "# h,c = enc(x)\n",
        "# # print(h.size(1)+c.size(1))\n",
        "# fus = Fusion(h.size(1))\n",
        "# h,c = fus([h], [c])\n",
        "# dec = Decoder()\n",
        "# print(\"size of x[:,-1,:,:,:]\", x[:,-1,:,:,:].size())\n",
        "# print(h.size())\n",
        "# out = dec(x[:,-1,:,:,:], h,c)\n",
        "# print(h.size())\n",
        "# print(c.size())\n",
        "# print(torch.cat([h,c], dim=1).size())"
      ],
      "metadata": {
        "id": "bGqnuSiHE2se"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}